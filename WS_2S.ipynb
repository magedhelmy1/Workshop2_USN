{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbb9d7-1eb3-4fed-91e0-cba624710c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install matplotlib -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13af81f-0104-41c6-8bac-76c6c0f0a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3759bec-0732-4b4a-ab4b-f92219dbc5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge opencv -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06702b9-6877-440b-b505-27c4dd7c5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge keras -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7360a8b-b60c-4217-b733-000d5d134790",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28184ed-1e7a-4b0e-9acd-0e0b2e71597f",
   "metadata": {},
   "source": [
    "# 1. Warm up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feeb589-de15-4362-8365-6561a5d98336",
   "metadata": {},
   "source": [
    "### 1.1 Inspecting an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28acdbea-e22e-447f-88c7-5ba8c95fa0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c59ad4-70b9-4dd0-8b00-ef63b15d9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94568bfe-7b77-4888-b16e-5a61e24f4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad44d57-725c-4f53-8b07-3a8d16aa82f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulate the colors  # Zero out contribution from red and green\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10511c16-0ae0-416c-a55d-9cddec703e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a406e82-5484-4864-9a16-df416df14e9d",
   "metadata": {},
   "source": [
    "### 1.2 Using different libraries to read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce814c2-a8c7-4a11-b351-7245a1df1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image\n",
    "img = cv2.imread('DATA/00-puppy.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6474a-4040-4120-8b02-341217cec335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view image, why is it different color?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edced04f-fcb9-404a-8fa3-83091bd21600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39734a4b-19c6-4260-aaa1-d71f0f49d5c9",
   "metadata": {},
   "source": [
    "## 2. MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4675c84-1afb-4062-bb1b-a7d2a99d1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in mnist dataset\n",
    "from keras.datasets import mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de5f76-2da4-4290-ad2e-e8726da2b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a05ea6-d7a1-4237-9af8-f262399cecfe",
   "metadata": {},
   "source": [
    "### 2.1 Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f87ab-ddf5-4bb6-91ff-6e3ffde61a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57e483-6d8d-405b-b8d6-690e67d676f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364370f8-cf72-4cb7-9b8f-1b50ed96d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26650227-8a59-4c40-bf1f-2fe6c331c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3eb945-1bfa-44af-8e48-6246119dddf9",
   "metadata": {},
   "source": [
    "### 2.2 PreProcessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cc932-f56b-4689-b592-ccf81996bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the y labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6841f-4cc9-4343-8bc1-426fb96b68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the test labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab05aa0-c0c8-47f2-89ad-6ff9863c479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import categorical\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b79e0-dbb2-4a90-b38c-d3a22efe5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66eb0ab-eca7-4b81-9905-a17a9477f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7a833-1c97-4e41-87a8-b4c4e3d17c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b111d7-09ba-4ec4-9bef-a0d9440107eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7401a49-ea75-4d9c-a586-6a44d568111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass number of classes of y_test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27f48b-f18f-4fc0-8c9d-faba90d5703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the number of classes to y_train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9518859-d243-40f5-8339-fdd507eaf4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check max value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0944009-a761-4229-9138-f19602c8bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check min value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a879ca-1653-41bf-a30d-0c5d608e71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114bc2b1-0bcd-43c5-b807-9bbab83d0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check new scaled value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5cad59-2505-4d8c-a19c-2ad03c522653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check max value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b71ba-8ca8-4e6c-9b84-9156438dc86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot imgae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ab540-bdce-4f25-9e68-b3e87151adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check x_train shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d81cca-6dd0-4dd3-9a33-9023053c929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check x_test shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e5b4c-15af-461a-8107-f84dcbda4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97dea6-5a51-46f5-90f6-8adf7499e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check x_train shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f318ef5-8ec6-4e7b-91e3-18b997c662cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape test value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce35d0-5e02-4691-816e-c246381ae5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check test shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac0a5d-f7c4-4e19-b6e1-80207f11f649",
   "metadata": {},
   "source": [
    "### 2.3 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab1894-3a5b-4a40-be27-67c1a1c47179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0dfd31-abd1-4152-9345-b04901552900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "# CONVOLUTIONAL LAYER\n",
    "\n",
    "# POOLING LAYER\n",
    "\n",
    "# FLATTEN IMAGES FROM 28 by 28 to 764 BEFORE FINAL LAYER\n",
    "\n",
    "# 128 NEURONS IN DENSE HIDDEN LAYER (YOU CAN CHANGE THIS NUMBER OF NEURONS)\n",
    "\n",
    "# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864e77a-8bb6-4fa4-b811-b646c59eeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d1e1a-4a28-481c-8feb-fe0af9cf044a",
   "metadata": {},
   "source": [
    "### 2.4 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fff2e2-6f5d-4d70-9ab5-fa524af07bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f23f5e-6bee-4c75-9ba6-1904cd801301",
   "metadata": {},
   "source": [
    "### 2.5 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14053076-33bd-4907-8faa-2f9843042883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e04db-bb99-489f-9c28-66db59a290e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c384ea-13d6-4deb-be16-d456356b525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6f4ed-1177-47c9-bc48-7a2e515b1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ff99b-ddf3-4b07-91f7-8ed531ce606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8b8d6-5175-4230-b674-d5310386541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check single value shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584c6a1-8d46-43fd-9241-62f9e4fc59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cehck single prediction shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47ed55-842d-42bc-ae02-5d16b5ad5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f8ad9-f33d-49e9-acff-28d3d2391ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2470dcc5-5d51-4729-9dbc-875fc80ddab7",
   "metadata": {},
   "source": [
    "## 3. CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00449b0a-c721-4afd-8ec0-63b4a275b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed2df3-143c-42a1-ba7c-adfc8ee785c2",
   "metadata": {},
   "source": [
    "### 3.1 Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f7cd8-4bdb-47bf-b480-eb136f70ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60996ed7-ebcd-4c1e-82ec-70be8a1f53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the first image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e84e82-a43a-4b37-9b77-1f1b5fb14c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b9b46-9fa4-4650-bd2c-5b19b6036112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the second image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add79e0-f83a-4e5c-88ce-6998fda34a7a",
   "metadata": {},
   "source": [
    "### 3.2 PreProcessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fca3e0-410b-4eea-bb13-a155738d90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the first object in the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945250d1-6c5c-4f00-b525-17410db8f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the max value in the first object in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25ed2d-3020-4b59-ad4b-778c5137c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d181ec-a9fc-4348-8472-bece894ca54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ce9c6-21e3-4cde-b1e1-eaf16e5f3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ce299-612d-4e06-8176-ec91d5f06046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c03fa-0595-48de-8030-e56496c1d183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1b1c5-ec27-4a77-acf6-d80d08ec3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63fc81-7cca-4995-8dec-bd3f68e833f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first objet in the labels set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea895cc-e919-47d7-925e-9f6c79d3bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training sets label to categorical\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806a035-b30f-4a3d-9317-3f8182c3bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the newly converted labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc61705-9aa3-401c-a954-ed88f2ef1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first object in the newly converted label variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3363c80-3a1f-4fbe-a767-a755726422a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the test label into categorical\n",
    "y_cat_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e350d71-471b-45a5-978d-68410bd9abaf",
   "metadata": {},
   "source": [
    "### 3.3 Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0b8ad-90d9-4a75-8b88-ea4195795a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaef7df-6c84-4276-a21c-d48048d88b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "## FIRST SET OF LAYERS\n",
    "\n",
    "# CONVOLUTIONAL LAYER\n",
    "# with 32 filters, size of 4 by 4, takes in a shape of 32 by 32 by 3, and has an activation of reul\n",
    "\n",
    "# POOLING LAYER\n",
    "# with size 2 by 2\n",
    "\n",
    "## SECOND SET OF LAYERS\n",
    "\n",
    "# CONVOLUTIONAL LAYER\n",
    "# with 32 filters, size of 4 by 4, takes in a shape of 32 by 32 by 3, and has an activation of reul\n",
    "\n",
    "# POOLING LAYER\n",
    "# with size 2 by 2\n",
    "\n",
    "# FLATTEN IMAGES\n",
    "\n",
    "# Create neurons layer of 256 NEURONS IN DENSE HIDDEN LAYER With activation of reulu\n",
    "\n",
    "# LAST LAYER IS THE CLASSIFIER, with an activation of softmax\n",
    "\n",
    "# compile with categorical_crossentropy, use an optimizer of 'rmsprop' and use the metric accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31060c91-a4a2-498e-9561-55e5c9122db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749fe0e-b78c-42d3-83da-fdb2e8806bb9",
   "metadata": {},
   "source": [
    "### 3.4 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1976351-e69c-4578-afe0-0b246acb1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with 10 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc52b75-f99a-43b4-a9c8-a8a7adad2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d722b7d-1889-4f74-8671-275259849d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c99b990-7916-4899-b159-7e8825a00c59",
   "metadata": {},
   "source": [
    "### 3.5 Evaluting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9245fa61-df3b-4252-95e9-6fd8361f4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the x_test set\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e7d30-d32a-425e-b164-e0e30fbd9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the classification report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a84975-39d5-470b-aee6-118b7888549f",
   "metadata": {},
   "source": [
    "## 4. Excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86fab3-8914-4104-bf4e-c996bc7e8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbbcd78-cc54-495b-9092-730d50efdef5",
   "metadata": {},
   "source": [
    "### 4.1 Visualizing the Data\n",
    "\n",
    "Use matplotlib to view an image from the data set. It can be any image from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd597db-2a17-446c-afa0-36399b53dac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90146d7b-53d7-4304-8ea1-99cf572a4b80",
   "metadata": {},
   "source": [
    "### 4.2 Preprocessing the Data\n",
    "\n",
    "Normalize the X train and X test data by dividing by the max value of the image arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7418243f-47eb-4007-a0f2-7a7426c8c135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6acddff5-9a4f-47d9-a48c-5d7ce7651c1b",
   "metadata": {},
   "source": [
    "### 4.3 Reshape the Data\n",
    "Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a619c-7e16-4eeb-8ccb-fef13bffec10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36fdae64-cdab-4759-8d30-6f5a22907266",
   "metadata": {},
   "source": [
    "### 4.4 Hot Encode the data\n",
    "Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553ca67-99bc-4f03-a6b8-aa590e71f541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "531fd95f-6df3-4a4e-978b-674bfe1004bf",
   "metadata": {},
   "source": [
    "## 4.5 Building the Model\n",
    "\n",
    "Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da423cfd-5f16-47e9-a3a7-865513e9c73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf8172e6-1271-4bfe-94c4-ba6946c168e5",
   "metadata": {},
   "source": [
    "### 4.6 Training the Model\n",
    "Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6993f-ee83-42db-8f96-e8ea2da6f0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "419393d8-98b5-46e6-8f4d-7b70d6bed36c",
   "metadata": {},
   "source": [
    "### 4.7 Evaluating the Model\n",
    "\n",
    "Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a397a1-a0a0-4ed2-8a00-0a7ebc383293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efe28f2b-a989-49d1-808a-ef39c113c192",
   "metadata": {},
   "source": [
    "## 5. Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4cc43-675e-40a9-a4d2-6210a1963edd",
   "metadata": {},
   "source": [
    "Use the COCO dataset whcih has 1.5 million object instances with 80 different object categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3655735-29c4-4d68-a2c1-52c576de9325",
   "metadata": {},
   "source": [
    "Download the pre-trained on COCO hear\n",
    "\n",
    "https://drive.google.com/u/0/uc?id=1yT2-zmNFymMgY42Z72LIuqMaiWvYEUQR&export=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca5ce41-8399-4e0f-828d-3642df29e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from YOLOV3.model.yolo_model import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4058928-d350-4530-9d10-40f2f438d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    \"\"\"Resize, reduce and expand image.\n",
    "\n",
    "    # Argument:\n",
    "        img: original image.\n",
    "\n",
    "    # Returns\n",
    "        image: ndarray(64, 64, 3), processed image.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17c52fc6-e383-4666-a202-23f0a67b9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(file):\n",
    "    \"\"\"Get classes name.\n",
    "\n",
    "    # Argument:\n",
    "        file: classes name for database.\n",
    "\n",
    "    # Returns\n",
    "        class_names: List, classes name.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfedc08e-1e8c-4b1e-9024-36206f4795ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image, boxes, scores, classes, all_classes):\n",
    "    \"\"\"Draw the boxes on the image.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        boxes: ndarray, boxes of objects.\n",
    "        classes: ndarray, classes of objects.\n",
    "        scores: ndarray, scores of objects.\n",
    "        all_classes: all classes name.\n",
    "    \"\"\"\n",
    "    for box, score, cl in zip(boxes, scores, classes):\n",
    "        x, y, w, h = box\n",
    "\n",
    "        top = max(0, np.floor(x + 0.5).astype(int))\n",
    "        left = max(0, np.floor(y + 0.5).astype(int))\n",
    "        right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n",
    "        bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n",
    "\n",
    "        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "        cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl], score),\n",
    "                    (top, left - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6, (0, 0, 255), 1,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "        print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))\n",
    "        print('box coordinate x,y,w,h: {0}'.format(box))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1773b760-fe8e-4eaf-af40-9ff887bf2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(image, yolo, all_classes):\n",
    "    \"\"\"Use yolo v3 to detect images.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        yolo: YOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "\n",
    "    # Returns:\n",
    "        image: processed image.\n",
    "    \"\"\"\n",
    "\n",
    "    pimage = process_image(image)\n",
    "\n",
    "    start = time.time()\n",
    "    boxes, classes, scores = yolo.predict(pimage, image.shape)\n",
    "    end = time.time()\n",
    "\n",
    "    print('time: {0:.2f}s'.format(end - start))\n",
    "\n",
    "    if boxes is not None:\n",
    "        draw(image, boxes, scores, classes, all_classes)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e96f33d-8cd2-4afb-958d-d5927b6578a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO(0.6, 0.5)\n",
    "file = 'YOLOV3/data/coco_classes.txt'\n",
    "all_classes = get_classes(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d91a2-98d6-477a-9fd9-6b97947fe95b",
   "metadata": {},
   "source": [
    "### 5.1 Detecting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "538b5289-bb6f-4130-b9cb-c75c2b8ddb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.84s\n",
      "class: person, score: 0.60\n",
      "box coordinate x,y,w,h: [2523.36752415 1482.90827608  621.14270031 1302.12939548]\n",
      "class: bicycle, score: 0.84\n",
      "box coordinate x,y,w,h: [2877.7012825  2007.04610348 1301.56517029  721.28452325]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'jingxiang-gao-489454-unsplash.jpg'\n",
    "path = 'YOLOV3/images/test/'+f\n",
    "image = cv2.imread(path)\n",
    "image = detect_image(image, yolo, all_classes)\n",
    "cv2.imwrite('YOLOV3/images/res/' + f, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
